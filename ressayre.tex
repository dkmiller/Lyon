\documentclass{article}

\usepackage{lyon-style}

\title{Representations of Quivers}
\author{Nicolas Ressayre}
\date{June 2-6, 2014}

\begin{document}
\maketitle
\tableofcontents





\section{Introduction}

Our main goal is Derkson and Weyman's proof of the following ``saturation 
theorem'' for $\generallinear(n)$. Throughout, all vector spaces, matrices, 
etc.\ are over the field of complex numbers $\dC$. 

\begin{theorem}
Let $\lambda$, $\mu$, $\nu$ be three partitions of length $n$. Let 
$V(\lambda)$, $V(\mu)$, $V(\nu)$ be the corresponding irreducible 
representations of $\generallinear(n)$. If there is $k>0$ such that 
$V(k\nu)\subset V(k\lambda)\otimes V(k\mu)$, then 
$V(\nu)\subset V(\lambda)\otimes V(\mu)$. 
\end{theorem}





\section{The category \texorpdfstring{$\representations(Q)$}{Rep(Q)}}

Recall that a \emph{quiver} is a finite oriented graph $Q=(Q_0,Q_1)$, where 
$Q_0$ is the set of vertices and $Q_1$ is the set of arrows. These sets are 
accompanied by maps $t,h:Q_1 \to Q_0$, which we think of as assigning to each 
arrow $a$ its ``head'' $h a$ and ``tail'' $t a$, as in the picture 
\[\xymatrix{
  t a \ar[r]^-a 
    & h a
}\]

\begin{example}
The following are graphical representations of quivers: 
\[\xymatrix{
  \bullet \ar[r] 
    & \bullet
}\]
\end{example}

A \emph{representation} of a quiver $Q$ is the data consisting of vector 
spaces $(V_x)_{x\in Q_0}$ and linear maps $(V(a))_{a\in Q_1}$, where 
$V(a):V(t a)\to V(h a)$ is an element of 
$\hom(V(t a),V(h a))$. 

\begin{example}
A representation of $\circlearrowright$ consists of a vector space together 
with an endomorphism. 
\end{example}

\begin{example}
A representation of $\bullet \to \bullet$ consists of a linear map between two 
vector spaces. 
\end{example}

A \emph{morphism} $V\to W$ between representations consists of linear maps 
$(\varphi_x)_{x\in Q_0}$ from $V(x)$ to $W(x)$, such that the following 
diagrams commute:
\[\xymatrix{
  V(t a) \ar[r]^-a \ar[d]^-{\varphi(t a)} 
    & V(h a) \ar[d]^-{\varphi(h a)} \\
  W(t a) \ar[r]^-a 
    & W(h a) 
}\]

The category $\representations(Q)$ has as objects representations of $Q$, and 
morphisms as just defined. 

\begin{example}
The isomorphism classes of objects in $\representations(\circlearrowright)$ 
consist of conjugacy classes of matrices. 
\end{example}

\begin{example}
Isomorphism classes of $\representations(\bullet \to \bullet)$ consist of 
matrices up to direct sum. 
\end{example}





\section{Path algebra \texorpdfstring{$\dC Q$}{C Q}}

Let $Q$ be a quiver. A \emph{path} $p$ in $Q$ is either 
\begin{enumerate}
  \item a sequence $a_1,\dots,a_n$ such that $t a_i = h a_{i+1}$ (we draw such 
    a sequence as 
    \[\xymatrix{
      \bullet \ar[r]^-{a_n} 
        & \bullet \ar[r] 
          & \cdots \ar[r] 
          & \bullet \ar[r]^-{a_1} 
          & \bullet )
    }\]
    where we put $t p = t a_n$ and $h p = h a_1$ 
  \item a path $e_x$ (the ``trivial path'') for each $x\in Q_0$, where we put 
    $t e_x = h e_x = x$. 
\end{enumerate}

Put $\dC Q = \bigoplus_{p\text{ path}} \dC p$. The product is given by 
concatenation (in the obvious way). Put $p p'=0$ if $h p'\ne t p$. 

\begin{example}
Consider $Q=\circlearrowright$. We have 
$\dC Q = \bigoplus_{n\geqslant 0} \dC x^n$, where 
$x^n = \overbrace{a \cdots a}^n$. In other words, $\dC Q$ is isomorphic to the 
polynomial ring $\dC[x]$. 
\end{example}

\begin{example}
Let $Q=1\xrightarrow a 2$. Then $\dC Q = \dC e_1 \oplus \dC e_2 \oplus \dC a$. 
Our multiplication table is 
\begin{center}
\begin{tabular}{c|ccc}
        & $e_1$ & $e_2$ & $a$ \\ \hline
  $e_1$ & $e_1$ & 0 \\
  $e_2$ & 0     & $e_2$ & $a$ \\
  $a$   & $a$   & 0     & 0
\end{tabular}
\end{center}
One can easily check that $\dC Q$ is isomorphic to the matrix algebra 
$\smat{\ast}{}{\ast}{\ast}$. 
\end{example}

\begin{proposition}
There is an exact equivalence of categories 
$\representations(Q) \simeq \modules(\dC Q)$. 
\end{proposition}
\begin{proof}
Send a $Q$-representation $V$ to the module $\bigoplus_{x\in Q_0} V(x)$, where 
``simple paths'' $t a \xrightarrow a h a$ act via $V(a)$, and general paths act 
via composition of simple paths. It is easy to check that this functor has the 
required properties. 
\end{proof}


% simple modules

Since $\representations(Q)$ is a $\dC$-enriched abelian category, it makes 
sense to talk about submodules, direct sums, simple modules, \ldots. 

\begin{example}
Let $x\in Q_0$. Define 
\[
  S^x(y) = \begin{cases} \dC & y=x \\ 0 & \text{otherwise} \end{cases} 
\]
and $S^x(a) = 0$ for all $a\in Q_1$. It is trivial that $S^x$ is a simple 
representation of $Q$. 
\end{example}

\begin{proposition}
If $Q$ has no cycle, then the $S^x$ are the only simple modules over $\dC Q$. 
\end{proposition}
\begin{proof}
We can filter $\dC Q$ by length. The subspace 
$(\dC Q)_{\geqslant 1} = \bigoplus_{\ell(p)\geqslant 1} \dC p$ of 
$\dC Q$ is actually an ideal. If $Q$ has no cycles, then 
$(\dC Q)_{\geqslant 1}^m = 0$ for $m\gg 0$. Let $S$ be a simple $Q$-module.
We cannot have $(\dC Q)_{\geqslant 1} S=S$ (non-commutative Nakayama 
lemma) so $(\dC Q)_{\geqslant 1} S = 0$. Thus $S$ is a 
$\dC Q/(\dC Q)_{\geqslant 1}=\dC^{Q_0}$-representation, whence the result.  
\end{proof}

\emph{Warning}: this does not imply that $\representations(Q)$ is a 
semisimple category. 


% indecomposable modules

Since the category $\representations(Q)$ is not generally semisimple, 
the class of indecomposable modules may be much bigger than the class of 
irreducible modules. 

\begin{example}
Let $Q=\circlearrowright$. Then for any $n\geqslant 1$ and 
$\lambda\in \dC$, the representation corresponding to the $n\times n$ matrix 
\[
  J_\lambda(n) = 
  \begin{pmatrix}
    \lambda & 1 & \cdots & 0\\
    & & \ddots & \vdots \\
    & & & 1 \\
    & & & \lambda
  \end{pmatrix} .
\]
\end{example}

\begin{lemma}\label{lem:inv-nil}
A representation $V$ of $Q$ is indecomposable if and only if its endomorphisms 
are either invertible or nilpotent. So $\End_Q(V) = \dC\oplus I$, where $I$ is 
the ideal of nilpotents. 
\end{lemma}
\begin{proof}
If $\varphi\in \End_Q(V)$, then $\varphi(x)\in \End(V(x))$ for each $x$. 
We have a decomposition 
$V(x) = V^{\lambda_1}(x) \oplus \cdots \oplus V^{\lambda_s}(x)$, where 
$V^{\lambda_i} = \ker(\varphi-\lambda_s\cdot 1)$. One can check that each 
$V^{\lambda_i}$  is a representation of $Q$. Since $V$ is indecomposable, 
$s=1$. Either $\lambda=0$ ($\varphi$ is nilpotent) or $\lambda\ne 0$ 
($\varphi$ is invertible). 
\end{proof}

\begin{exercise}
Show that $\bullet \to \bullet$ has exactly three indecomposable 
representations. 
\end{exercise}

\begin{theorem}[Krull-Schmidt]\label{thm:krull-schmidt}
Any representation of $Q$ can be decomposed uniquely as a direct sum of 
indecomposable representations. 
\end{theorem}

\begin{corollary}[Jordan]
Any matrix is conjugate to a unique one of the form 
\[
  \begin{pmatrix}
    J_{\lambda_1}(n_1) & & 0\\
    & \ddots \\
    0 & & J_{\lambda_s}(n_s) 
  \end{pmatrix} .
\]
\end{corollary}

\begin{example}
The only irreducible representations of $\bullet \to \bullet$ are 
$\dC \to 0$, $0 \to \dC$, and $\dC \xrightarrow 1 \dC$. From the Krull-Schmidt 
theorem we see that for all matrices $M\in M_{p,q}(\dC)$, there exist 
invertible $P,Q$ such that 
\[
  M = P 
  \begin{pmatrix} 
    1 \\
    & \ddots \\
    & & 1 \\
    & & & 0 \\
    & & & & \ddots \\
    & & & & & 0
  \end{pmatrix} Q .
\]
\end{example}


% projective modules

Recall that a representation $P$ of $Q$ is \emph{projective} if the functor 
$\hom_Q(P,-)$ is exact. This is equivalent to the more familiar definition 
involving lifts of morphisms as in the following diagram:
\[\xymatrix{
  & V \ar@{->>}[d]^-\pi \\
  P \ar[r]^-\varphi \ar@{.>}[ur]^-{\widetilde\varphi}
    & W .
}\]

\begin{example}
For any $x\in Q_0$, then $P^x = \dC Q\cdot e_x = \bigoplus_{t p=x} \dC p$ is a 
projective $Q$-module. 
\end{example}

Note that $P^x(y) = \bigoplus_{p:x\to y} \dC p$, i.e.\ $P^x(y)$ has as basis 
the paths from $x$ to $y$. The map $P^x(a):P^x(t a) \to P^x(h a)$ is just 
``concatenate with $a$.'' For any 
$V\in \representations(Q)$, there is a natural isomorphism of vector spaces 
$\hom_Q(P^x,V)\isomorphism V(x)$ given by $\varphi\mapsto \varphi(e_x)$. From 
this we can show that $P^x$ is projective. Indeed, suppose 
$0 \to Z \to V \to W \to 0$ is an exact sequence. It trivially follows that 
in $0 \to \hom(P,Z) \to \hom(P,V) \to \hom(P,W) \to 0$ is exact on the 
left, so the only hard part is to show that 
$\hom(P,V) \to \hom(P,W)$ is surjective. But all we need to do is show that 
$V(x) \to W(x)$ is surjective, and this is easy. 

Alternatively, we could have used the fact that 
$\dC Q=\bigoplus_{x\in Q_0} P^x$. 

\begin{proposition}
The modules $\{P^x:x\in Q_0\}$ are exactly the indecomposable projective 
modules over $Q$. 
\end{proposition}
\begin{proof}
We have already checked that the $P^x$ are projective. To show that they are 
indecomposable, we apply Lemma \ref{lem:inv-nil} to the fact 
$\End_Q(P^x) = P^x(x) = \dC e_x$. Clearly the $P^x$ are pairwise 
non-isomorphic, so all that remains is to show that an arbitrary 
indecomposable projective $P$ is one of the $P^x$. Consider the map 
$\bigoplus_{x\in Q_0} \dC Q\otimes P(x) \twoheadrightarrow P$ given by 
$p\otimes v\mapsto p v$. But 
$\bigoplus_{x\in Q_0} \dC Q\otimes P(x) = (\dC Q)^{\oplus N}$ for some $N$. 
Consider the exact sequence 
\[\xymatrix{
  0 \ar[r] 
    & Z \ar[r] 
    & (\dC Q)^{\oplus N} \ar[r] 
    & P \ar[r] 
    & 0 .
}\]
Since $P$ is projective, this sequence splits. So as a representation of $Q$, 
$(\dC Q)^{\oplus N} = P\oplus Z$. But 
$\dC Q^{\oplus N} = \bigoplus_{x\in Q_1} (P^x)^{\oplus N}$. By the Krull-Schmidt 
Theorem \ref{thm:krull-schmidt}, we conclude that $P=P^x$ for some $x$. 
\end{proof}


% projective resolutions

Let $V\in \representations(Q)$. There is an exact sequence 
\[\xymatrix{
  0 \ar[r] 
    & \displaystyle\bigoplus_{a\in Q_1} P^{h a} \otimes V(t a) \ar[r] 
    & \displaystyle\bigoplus_{x\in Q_0} P^x\otimes V(x) \ar[r] 
    & V \ar[r] 
    & 0 ,
}\]
in which the first map is 
$e^{h a}\otimes v\mapsto e^{ha}\otimes a  - a\otimes v$, and the second is 
$p\otimes v\mapsto p v$. We often write this as 
$0 \to P_1 \to P_0 \to P \to 0$, or $P_\bullet \to P$. This is the 
``standard projective resolution'' of $P$. 

For $W\in \representations(Q)$, we can apply $\hom_Q(-,W)$ to 
$P_\bullet \to P$, yielding a sequence 
\[
  0 \to \hom_Q(V,W) \to \hom_Q(P_0,W) \to \hom_Q(P_1,W) .
\]
We put $\extensions^1(V,W) = \hom(P_1,W) / \image(\hom(P_0,W))$. 
Recall that $\extensions^1(V,W)$ has an interpretation in terms of ``extensions.'' An 
\emph{extension} of $V$ by $W$ is an exact sequence 
\[
  0 \to W \to F \to V \to 0 
\]
of $Q$-modules. There is an obvious notion of isomorphism of extensions of 
$V$ by $W$. For any such extension, we can choose isomorphisms 
$F(x) = W(x)\oplus V(x)$. The structure of a $Q$-representation on $F$ is given 
by an element of $\bigoplus_{a\in Q_1} \hom(V(t ),W(h a)) = \hom(P_1,W)$. It is 
an easy exercise to check that two elements of $\hom(P_1,W)$ give equivalent 
extensions if and only if they differ by an element of $\image(\hom(P_0,W))$. 
In other words, $\extensions^1(V,W)$ classifies extensions of $V$ by $W$. 

For $\alpha,\beta\in \dZ^{Q_0}$, define 
\[
  \langle \alpha,\beta\rangle = \sum_{x\in Q_0} \alpha(x) \beta(x) - \sum_{a\in Q_1} \alpha(t a) \beta(h a) .
\]
If $V$ and $W$ are representations of $Q$, one has 
\[
  \langle \dim V,\dim W\rangle = \dim \hom_Q(V,W) - \dim \extensions_Q^1(V,W) .
\]





\section{Gabriel's theorem}

Fix a dmension vector $\beta\in \dN^{Q_0}$. For all $x\in Q_0$, put 
$V(x)=\dC^{\beta(x)}$; this is a vector space of dimension $\beta(x)$. Define 
$\representations(Q,\beta) = \bigoplus_{a\in Q_1} \hom(V(t a),V(h a))$. A point 
in $\representations(Q,\beta)$ gives a representation of $Q$. There is an 
action of $G(Q,\beta) = \prod_{x\in Q_0} \generallinear(V(x))$ on 
$\representations(Q,\beta)$ by 
$(\varphi\cdot R)(a) = \varphi(h a)\circ R(a)\circ \varphi(t a)^{-1}$. Note 
that $R_1$ and $R_2$ induce isomorphic representations if and only if they 
belong to the same orbit in $\representations(Q,\beta)$. Moreover, 
$\langle \beta,\beta\rangle = \dim G(Q,\beta)-\dim \representations(Q,\beta)$. 

Fix a point $R\in \representations(Q,\beta)$. Then the 
$G(Q,\beta)_R$ is connected. Let 
$\xi\in \lie(G(Q,\beta)_R) = \bigoplus_{x\in Q_0} \End(V(x))$. Then 
$\xi\cdot R=0$ if and only if 
$\xi(h a)\circ R(a)-R(a)\xi(h a) = 0$ for all $a$, which in turn is equivalent 
to $\xi\in \End_Q(V)$. 

Let's look at orbits. Put $\fg=\lie(G(Q,\beta)_R)$. There is an exact 
sequence $0 \to \End_Q(V) \to \fg \to T_R (G\cdot R)\to 0$, so one can check 
that $\extensions_Q^1(V,V) = \representations(Q,\beta)/T_R(G\cdot R)$. In 
particular, the codimension of the orbit $G\cdot R$ is the dimension of 
$\extensions_Q(V,V)$. 

\begin{definition}
A \emph{root lattice} is a pair $(\Lambda,\langle\cdot,\cdot\rangle)$ with 
\begin{enumerate}
  \item $\Lambda$ a finite free abelian group, 
  \item $\langle\cdot,\cdot\rangle$ a Euclidean product on $\Lambda_\dR$ 
  \item for all $\alpha\in \Lambda$, $\langle \alpha,\alpha\rangle\in 2\dZ$ 
  \item $\Lambda=\dZ\cdot \{\alpha\in \Lambda:\langle \alpha,\alpha\rangle=2\}$. 
\end{enumerate}
\end{definition}

\begin{example}
Any simply laced root system $\Phi\subset E$ works. Fix the $W$-invariant 
inner product $\langle\cdot,\cdot\rangle$ such that 
$\langle\alpha,\alpha\rangle = 2$ for all $\alpha\in \Phi$. Then 
$(\dZ\cdot \Phi,\langle\cdot,\cdot\rangle)$ is a root lattice. 
\end{example}

\begin{theorem}
All root lattices come from a simply-laced root system of type $A$, $D$, or 
$E$. 
\end{theorem}

We wish to understand how to go from a root lattice to a root system. Given 
$(\Lambda,\langle\cdot,\cdot\rangle)$, put 
$\Phi = \{\alpha\in \Lambda:\langle\alpha,\alpha\rangle = 2\}$. We also want to 
recover the Dynkin diagram of $\Phi$. Let 
$\Delta=\{\varepsilon_1,\dots,\varepsilon_n\}$ be a basis of $\Phi$. The 
Dynkin diagram has $\Delta$ as vertices, with 
$|\langle \varepsilon_i,\varepsilon_j\rangle|$ the number of edges between  
$\varepsilon_i$ and $\varepsilon_j$. 

\begin{example}
The simply-laced Dynkin diagrams look like: 
\begin{align*}\tag{A}
\xymatrix@=0.5cm{
  \bullet \ar@{-}[r] 
    & \bullet \ar@{-}[r] 
    & \cdots \ar@{-}[r] 
    & \bullet \ar@{-}[r] 
    & \bullet 
} \\
\tag{D}
\xymatrix@=0.5cm{
  \bullet \ar@{-}[r] 
    & \bullet \ar@{-}[r] 
    & \cdots \ar@{-}[r] 
    & \bullet \ar@{-}[d] \ar@{-}[r] 
    & \bullet \\
    & & & \bullet
}\\
\tag{E6-E8}
\xymatrix@=0.5cm{
  \bullet \ar@{-}[r] 
    & \cdots (\text{0 to 2})\cdots\ar@{-}[r] 
    & \bullet \ar@{-}[d] \ar@{-}[r] 
    & \bullet \ar@{-}[r] 
    & \bullet \\
    & & \bullet
}
\end{align*}
\end{example}

A quiver $Q$ is said to be of \emph{finite type} if it has only finitely many 
indecomposable representations of any given dimension. 

\begin{theorem}[Gabriel]
A quiver $Q$ is of finite type if and only if each connected component of $Q$ 
is a simply-laced Dynkin diagram. 
\end{theorem}
\begin{proof}
$\Rightarrow$. We may assume that $Q$ is connected and of finite type. We put 
$\langle \alpha,\beta\rangle_s = \langle \alpha,\beta\rangle + \langle \beta,\alpha\rangle$; 
this is the symmetric part of our form on $\dZ^{Q_0}$. First, one checks that 
$\langle\cdot,\cdot\rangle_s$ is Euclidean. Let $\alpha\in \dN^{Q_0}\smallsetminus \{0\}$. 
Then $G(Q,\alpha)$ acting on $\representations(Q,\alpha)$ has infinitely 
many orbits, so $\dim G(Q,\alpha) \geqslant \dim\representations(Q,\alpha)$. 
Thus $2\langle \alpha,\alpha\rangle_s\geqslant 0$. We can further mod out by 
the action of $\dC^\times$, obtaining $2\langle \alpha,\alpha\rangle_s>0$. 

If $\beta\in \dZ^{Q_0}\smallsetminus \{0\}$, then 
$\langle \beta,\beta\rangle_s\geqslant \langle |\beta|,|\beta|\rangle_s > 0$, so 
$\langle\cdot,\cdot\rangle_s$ is indeed Euclidean. 

We still need to check that for $\alpha\in \dZ^{Q_0}$, we have 
$\langle \alpha,\alpha\rangle_s\in 2\dZ$. But this follows from the easy 
fact that $\langle\varepsilon_s,\varepsilon_x\rangle_s = 2$, for 
$\varepsilon_x(y) = \delta_{x y}$. 
Thus $(\dZ^{Q_0}, \langle \cdot,\cdot\rangle_s)$ is a root lattice (often 
called the \emph{Tits form} of our lattice). 

Finally, we need to check that the Dynkin diagram associated to 
$(\dZ^{Q_0}, \langle \cdot,\cdot\rangle_s)$ is $Q$. In other words, we need 
that for $x\ne y$, 
$\langle \varepsilon_x,\varepsilon_y\rangle = \pm \#\{\text{edges between $x$ and $y$}\}$. 
This can be done directly. 

The only thing missing is that we need to prove $(\varepsilon_x)_{x\in Q_0}$ is 
a basis of $\Phi$. Some ``futsing around'' yields that for 
$\beta\in \Phi$, $\langle \beta,\beta\rangle_s = 2$, whence 
$\beta(t a) \beta(h a) \geqslant 0$ for all $a$. 
\end{proof}

In particular, ``having finite type'' does not depend on the orientation. 

\begin{theorem}
Let $Q$ be of type ADE. Set 
$\Phi^+=\{\alpha\in \dZ^{Q_0}:\langle \alpha,\alpha\rangle_s = 2\}$. Then 
\[
  \Phi^+=\{\dim V:V\text{ an indecomposable representation of }Q\} .
\] 
\end{theorem}
\begin{proof}
Choose a bijection \(Q=\{1,\dots,m\}\) such that \(t a>h a\) for all 
\(a\in Q_1\). Now consider the functor 
\(C^+=C_n^+ \circ \cdots \circ C_1^+:\representations(Q) \to \representations(Q)\). 
Let \(c=s_n\circ \cdots \circ s_1:\dZ^{Q_0}\to \dZ^{Q_0}\). One needs Lemma 
\ref{lem:tech-dynkin}. 

$\supset$. Let \(V\) be an indecomposable representation of \(Q\). Apply 
\(C_1^+\), \(C_2^+\), \ldots,\(C_n^+\), \(C_1^+\),\ldots to \(V\) up to obtaining 
\(0\) (this occurs because of the Lemma). Thus some 
\(C_\ell^+(C_{\ell-1}^+ \circ \cdots \circ C_1^+ V)=0\), hence 
\(C_{\ell-1}^+ \circ \cdots \circ C_1^+ = S^\ell\). Thus 
\(W\cdot \dim V\ni \varepsilon_\ell\), hence 
\(\dim V\in \Phi\). 

\(\subset\). Let \(\alpha\in \Phi^+\). Apply \(s_1 s_2 \dotsm s_m s_1 s_2 \dotsm\) 
to \(\alpha\) up to getting a negative root. So 
\(s_\ell(s_{\ell-1} \dotsm s_1 \alpha)\in \Phi^-\), but 
\(s_{\ell-1} \dotsm s_1 \alpha\in \Phi^+\). It follows that 
\(s_{\ell-1} \dotsm s_1 \alpha=\varepsilon_\ell\). Define 
\(V=C_1^- \dotsm C_{\ell-1}^- S^\ell\). 
\end{proof}

The main tool in the proof is Coxeter functor. The hard part here is constructing 
the indecomposable representations corresponding to dimension vectors. Note that 
$\varepsilon_x = \dim S^x$. Since the $\varepsilon_x$ are the simple roots, we 
want to use the action of the Weyl group $W$ to deduce the general case from this 
one. Set $s_x:\dZ^{Q_0} \to \dZ^{Q_0}$ (the simple reflection associated to $x$) 
to be $\beta\mapsto \beta-\langle \beta,\varepsilon_x\rangle \varepsilon_x$. One 
has 
\[
  s_x\beta(y) = 
  \begin{cases}
    \beta(y) & y\ne x \\
    \sum_{t a=x} \beta(h a) + \sum_{h a=x} \beta(t a)-\beta(x) & y=x
  \end{cases}
\]
Assume that $x$ is a \emph{sink}, i.e.\ that all arrows incident to $x$ point 
to $x$. Then we define a map 
$C_x^+:\representations(Q,\beta) \to \representations(Q,s_x\beta)$. 
Let $V\in \representations(Q,\beta)$. We will define $W=C_x^+ V$. Put 
$W(y)=V(y)$ if $y\ne x$. Let $W(x)$ be the kernel of 
$\bigoplus_{h a=x} V(t a) \to V(x)$. Also, define 
\[
  W(a) = 
  \begin{cases}
    V(a) & t a\ne x\text{ and }h a\ne x \\
    W(a) & ha =x
  \end{cases}
\]

Now we want to define a functor $C_x^+:\representations(Q) \to \representations(s_x Q)$. 
To do this, we first need to define $s_x Q$. First let $\Gamma$ be the undirected 
graph associated to $Q$. Note that 
$2^{\Gamma_1}=\{\text{quivers supported by }\Gamma\}$. 

First define \(S_x:2^{\Gamma_1} \to 2^{\Gamma_1}\) by sending \(Q\) to the quiver 
given by reversing arrows \(a\) with \(t a=x\) or \(h a=x\). 
Assume that \(V\in \representations(Q)\) is indecomposable. We want to define 
\(C_x^+ V\). First put \(V'(y)=V(y)\) if \(y\ne x\), and 
\(V'(x) = \image(\bigoplus_{h a=x} V(t a) \to V(x))\). We know that 
\(V=V'\oplus V_1\). If \(V'\ne 0\), then \(V=S^x\). 

\begin{theorem}[Bernstein-Gelfand]
Let \(x\in Q_0\) be a sink, \(V\) an indecomposable representation of \(Q\). 
Then one of the following occurs:
\begin{enumerate}
  \item \(V\simeq S^x\) (which happens if and only if \(\dim V=\varepsilon_x\)), in which 
    case \(C_x^+ V=0\). 
  \item \(\dim V\ne \varepsilon_x\), whence \(C_x^+ V\) is an indecomposable 
    representation of \(\dim S_x\beta\). 
\end{enumerate}
\end{theorem}
\begin{proof}
We have a kind of inverse of \(C_x^+\) that preserves direct sums. There exists 
\(C_x^-:\representations(Q) \to \representations(s_xQ)\), so long as \(x\) is a 
source. It is analogous (or a ``dual'') of \(C_x^+\). In case 2 above, we have 
\(C_x^- C_x^+ V = V\). 
\end{proof}

\begin{lemma}\label{lem:tech-dynkin}
For all \(\alpha\in \dN^{Q_0}\smallsetminus \{0\}\), there exists $k$ such that 
\(c^k(\alpha)\not\in \dN^{Q_0}\smallsetminus \{0\}\). 
\end{lemma}
\begin{proof}
Since \(c\) is an element of the Weyl group of \(\Phi\), there exists 
\(k_0\) such that \(c^{k_0} = 1_{\dZ^{Q_0}}\). 
Thus \(\alpha+c \alpha+ \cdots + c^{k_0-1}\alpha = 0 \), whence there is 
\(1\leqslant k<k_0\) satisfying the lemma. 
\end{proof}





\section{Semi-invariants of quivers}


\subsection{Motivation}

Fix a quiver $Q$ without oriented cycles. Let $\beta\in \dN^{Q_0}$ be a dimenson 
vector. We have seen that the set of isomorphism classes of $Q$-representations 
with dimension vector $\beta$ is in bijection with 
$\representations(Q,\beta)/\generallinear(Q,\beta)$. As a scheme, this should 
have  coordinate ring $\dC[\representations(Q,\beta)]^{\generallinear(Q,\beta)}$, 
but this fixed ring is $\dC$. Instead, suppose we have 
$b_1/b_2\in \dC(\representations(Q,\beta))^{\generallinear(Q,\beta)}$. Then 
there exists $\sigma\in X^\ast(\generallinear(Q,\beta))$ such that 
$g b_1 = \sigma(g) b_1$ and $g b_2 = \sigma(g) b_2$. The set of 
\emph{semi-invariants} of $Q$ is 
\[
  \semiinvariant(Q,\beta)_\sigma = \{b_1\in \dC[\representations(Q,\beta)]:g b_1 = \sigma(g)b_1\} .
\]
Define 
\[
  \semiinvariant(Q,\beta) = \bigoplus_{\sigma\in X^\ast} \semiinvariant(Q,\beta)_\sigma = \dC[\representations(R,\beta)]^{\speciallinear(Q,\beta)} ,
\]
where $\speciallinear(Q,\beta) = \prod_{x\in Q_0} \speciallinear(\beta(x),\dC)$. 
Essentially, we are looking at the quotient 
$\representations(Q,\beta) /\speciallinear(Q,\beta)$. 

\begin{theorem}[Kac]\label{thm:kac}
Fix a sink $x$ of $Q$. Assume $s_x \beta\in \dN^{(s_x Q)_0}$. Then 
$\semiinvariant(Q,\beta) \simeq \semiinvariant(s_x Q,s_x \beta)$. 
\end{theorem}
\begin{proof}
[I think that we are relating $V(x)$ and $V'(x)$, where $V$ lives in 
$\semiinvariant(Q,\beta)$ and $V'$ lives in $\semiinvariant(s_x Q,s_x \beta)$.]

Set $W(x) = \bigoplus_{h a=x} V(t a)$. 
We have the following equalities:
\begin{align*}
  \representations(Q,\beta) &= \representations(Q\smallsetminus \{x\},\beta)\oplus \hom(W(x),V(x)) \\
  \representations(s_x Q,s_x \beta) &= \representations(Q\smallsetminus \{x\},\beta)\oplus \hom(V'(x),W(x)) \\
  \generallinear(Q,\beta) &= \generallinear(Q\smallsetminus \{x\},\beta) \times \generallinear(V(t a)) \\
  \generallinear(s_x Q,s_x \beta) &= \generallinear(Q\smallsetminus \{x\},\beta) \times \generallinear(V'(x)) \\
  \semiinvariant(Q,\beta) &= \left(\dC[\representations(Q\smallsetminus \{x\},\beta)]\otimes \dC[\hom(W(x),V(x))]^{\speciallinear(V(x))}\right)^{\speciallinear(Q\smallsetminus \{x\})} \\
  \semiinvariant(s_x Q,s_x \beta) &= \left(\dC[\representations(Q\smallsetminus \{x\},\beta)\otimes \dC[\hom(V'(x),W(x))^{\speciallinear(V'(a))}\right)^{\speciallinear(Q\smallsetminus\{x\})} .
\end{align*}
This can be explained by the fact that 
$\grassmannian(d,n) \simeq \grassmannian(n\cdot d,n)$. 

Note that $X^\ast(\generallinear(Q,\beta))\simeq \dZ^{Q_0}$ naturally. Put 
$s_x \sigma = y\mapsto \sigma(y) + \sigma(x) b_{x,y}$ if $y\ne x$, and 
$s_x \sigma :x\mapsto -\sigma(x)$, where $b_{x,y}$ is the number of edges between 
$x$ and $y$. 
\end{proof}
More precisely, we have 
$\semiinvariant(Q,\beta)_\sigma \simeq \semiinvariant(s_x Q,s_x \beta)_{s_x \sigma}$. 


\subsection{Schofield's semi-invariants}

Fix $\alpha\in \dN^{Q_0}$ such that $\langle \alpha,\beta\rangle = 0$. We defined 
a map 
\[
  P_0 = \bigoplus_{x\in Q_0} \hom(V(x),W(x)) \to \bigoplus_{a\in Q_1} \hom(V(t a), W(t a))= P_1 
\]
for any $V,W$ of dimension $\alpha$ and $\beta$. So we have 
$\representations(Q,\alpha)\times \representations(Q,\beta) \to \hom(P_0,P_1)$. 
Compose this with the determinant map to get 
\[
  C:\representations(Q,\alpha)\times \representations(Q,\beta) \to \textstyle\bigwedge^N P_0^\vee\otimes \bigwedge^N P_1\simeq \dC \qquad (V,W)\mapsto C_V^W ,
\]
where $N=\dim P_0=\dim P_1$. The map $C$ is 
$\speciallinear(Q,\alpha)\times \speciallinear(Q,\beta)$-invariant. So for any 
$V\in \representations(Q,\alpha)$, we have 
$C_V\in \semiinvariant(Q,\beta)_{\langle \alpha,-\rangle}$. 

The map $X^\ast(\generallinear(Q,\alpha))\times \dZ^{Q_0} \to \dZ$ given by 
$(\sigma,\gamma)\mapsto \sum_x \sigma(x) \gamma(x)$ is a perfct pairing, 
identifying $X^\ast(\generallinear(Q,\alpha))$ with $\hom(\dZ^{Q_0},\dZ)$. The 
latter space has $\langle \alpha,-\rangle$ as an element. 

\begin{theorem}[Derksen, Weyman]
Fix $Q$, $\beta$, and $\sigma$ as before. Consider $\alpha\in \dZ^{Q_0}$ with 
$\langle \alpha,-\rangle = \sigma$. Then $\semiinvariant(Q,\beta)_\sigma$ is 
the $\dC$-span of $\{C_V:V\in \representations(Q,\alpha)\}$. 
\end{theorem}
\begin{proof}[Idea of proof]
We use two reductions, and an explicit computation for the quiver $\Theta(m)$ with 
only two vertices, and $m$ edges from one to the other. 

Reduction 1. We aim to use Theorem \ref{thm:kac}. Define $\widetilde Q$ by adding 
a source and a sink to $Q$. In other words, $\widetilde Q_0 = Q_0\cup \{x_\pm\}$. 
We add an arrow $x_- \to y$ if $\sigma(y)<0$, and add an arrow 
$y\to x_+$ if $\sigma(y)>0$. Set 
\[
  \widetilde\sigma(y) = 
  \begin{cases}
    0 & y\ne x \\
    1 & y=x_- \\
    -1 & y=x_+ 
  \end{cases}
\]
We also define 
\[
  \widetilde\beta(x_\pm) = 
  \begin{cases}
    \sum_{\substack{y\in Q \\ \sigma(y)>0}} \sigma(y) \beta(y) & \text{if }+ \\
    \sum_{\substack{y\in Q \\ \sigma(y)<0}} -\sigma(y) \beta(y) & \text{if }- 
  \end{cases}
\]
and $y=\beta(y)$. Actually, 
$\widetilde\beta=s_{x_+}s_{x_-} \beta$ and 
$\widetilde\sigma=s_{x_+}s_{x_-} \sigma$. 

[\ldots stopped taking notes\ldots]
\end{proof}






\end{document}
